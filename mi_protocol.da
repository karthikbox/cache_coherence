"""
    MI cache coherence protocol implementation in DistAlgo
    based on the online implementation - https://github.com/samuelbritt/CS6290-prj3
    
    To implement the protocol in DistAlgo, we are using a combination of snooping 
    protocol logic and directory protocol logic.
    
    This DIstAlgo implementation is based on the C++ MI protocol implemenation found in
    https://github.com/samuelbritt/CS6290-prj3/blob/master/protocols/MI_protocol.cpp by Samuel Britt
    
    Note: Certain parts of the implementation are same for our group as they are generic classes/methods
          which are common to all protocols and is part of the intial setup. The other members of the group are
          Parag Gupta, Karthik Reddy, Garima Gehlot and Amit Kandelwal. I have mentioned the author/source in 
          the comments section of the appropriate classes/methods.

"""

import sys
import time
import os

ENOTSUPP = 2
CACHE_SIZE = 512

def get_proto_class(name):
  """
        return the corresponding protocol class name and controller name
        generic to all protocol implementations
        Reference : Parag Gupta (https://github.com/karthikbox/cache_coherence/tree/p_template/main.da)
  """
  if name == "MI":
    return (eval("MI_PROTO_CACHE"), eval("MI_PROTO_CTRL"))
  else:
    exit(-ENOTSUPP)

class MI_PROTO_CACHE(process):
  """
  MI Protocol Class:
     - This class handles both the caching logic as well as the protocol logic
     - snooping of caches and getting data from memory happens via message passing 
     - Each processor will have a protocol cache process corresponding to it which will maintain that processor's cache memory as well as maintain cache coherence
     - Inherits from the process class in DistAlgo
  """

  def setup(mem_ctrl_protocol_obj, other_protocol_obj, size, monitor_obj):
    self.memory = []
    self.get_from_caches = False
    self.wait_for_caches = False
    self.wait_for_memory = False
    self.get_from_memory = False
    self.not_found_q = []
    self.pending_actions = []
    
  def run():
    await(False)

  def reorder(addr, value):
    """
    LRU Caching logic
    """
    """ Check if the addr is present in the list """
    found = False
    for (state, address, val) in self.memory:
      if state == 1 and address == addr:
        found = True
        if value == "":
          #output(self.memory)
          value = val
        #output("found", value, "::", val)
        self.memory.remove((1, addr, val))
        break
    
    if not found:
      """ Check if the cache is full """
      if value == "":
        get_addr(addr)
        for (state, address, val) in self.memory:
          if state == 1 and address == addr:
            found = True
            if value == "":
              #output(self.memory)
              value = val
            #output("found", value, "::", val)
            self.memory.remove((1, addr, val))
            break
      if len(self.memory) == size:
        print("Cache is full")
        (state, last_addr, value) = self.memory.pop()
        if state == 1:
          send(('flush', last_addr, value), to=mem_ctrl_protocol_obj)
          send(('inc_msg_cnt', 1), to=monitor_obj)
   
    #output("reordering with value:", value) 
    self.memory.insert(0, (1, addr, value))
    return value

  def get_addr(addr):
    """
    The load/store address is not in the cache, try
       (1) snoop other caches 
       (2) if (1) fails then get from memory
    """

    wait_for_caches = False;
    #print(addr)
    send(('get', addr), to=other_protocol_obj)
    send(('inc_msg_cnt', len(other_protocol_obj)), to=monitor_obj)
    #print("awaiting for caches")
    await(wait_for_caches)
    if not get_from_caches:
      wait_for_memory = False
      #output(memory)
      send(('get', addr, self.id), to=mem_ctrl_protocol_obj)
      send(('inc_msg_cnt', 1), to=monitor_obj)
      #print("awaiting for memory")
      await(wait_for_memory)
    get_from_caches = False

  def receive(msg= ('get',addr), from_= p):
    """
    Received request for address from another cache, check local
    cache and if addr is present, invalidate it and send back the value
    """
    """ Add time delay here to mimic cache-to-cache latency """
    #print("Cache request for address: ", addr)
    #output(self.memory)
    found = False
    value = ""
    for i in range(len(self.memory)):
      ## invalidate cache block
      if self.memory[i][0] == 1 and self.memory[i][1] == addr:
        #output("Invalidating in address:", addr, "::", self.memory[i][2])
        value = self.memory[i][2]
        #output(self.memory)
        self.memory[i] = (0, addr, self.memory[i][2])
        #output(self.memory)
        found = True
        break
    if found:
      send(('found_in_cache', addr, value), to=p)
      send(('inc_msg_cnt', 1), to=monitor_obj)
    else:
      send(('not_found_in_cache', addr), to=p)
      send(('inc_msg_cnt', 1), to=monitor_obj)

  def receive(msg= ('invalidate', addr), from_= p):
    """
    Invalidate the cache block containing the requested address if present in our cache
    """
    """ invalidate cache block """
    for i in range(len(self.memory)):
      """ invalidate cache block """
      if self.memory[i][0] == 1 and self.memory[i][1] == addr:
        #output("Invalidating address:", addr, self.memory)
        self.memory[i] = (0, addr, self.memory[i][2])
        break

  def receive(msg=('found_in_cache', addr, value)):
    """
    Received "found in cache" acknowledgement which basically denotes we have found the requested addr in another cache and received the value from that cache.
    """
    #print("Addr:", addr, "received from another cache with value:", value, self.id)

    """ Check if the cache is full """
    if len(self.memory) == size:
      print("Cache is full")
      (state, last_addr, v) = self.memory.pop()
      if state == 1:
        send(('flush', last_addr, v), to=mem_ctrl_protocol_obj)
        send(('inc_msg_cnt', 1), to=monitor_obj)

    #output("found in cache: Appending value for address:",addr, "with value:", value)
    self.memory.append((1, addr, value))
    #output(self.memory)
    get_from_caches = True
    wait_for_caches = True

  def receive(msg=('get_from_cache', addr)):
    """
    Data already loaded into a cache. Snoop again
    """
    wait_for_memory = True
    not_found_q.clear()
    get_addr(addr)

  def receive(msg=('not_found_in_cache', addr)):
    """
    Received "not found in cache" from another cache.
    """
    not_found_q.append("recvd_not_found")
    #output("size of not found q:", len(not_found_q), addr)
    if len(not_found_q) == len(other_protocol_obj):
      #print("Addr", addr, "not found in the other caches")
      wait_for_caches = True 

  def receive(msg=('found_in_memory', addr, value)):
    """
    We have received the requested address/data from the memory controller
    """
    #print("Addr:", addr, "received from another cache with value:", value)
    """ Check if the cache is full """
    if len(self.memory) == size:
      print("Cache is full")
      (state, last_addr, v) = self.memory.pop()
      if state == 1:
        send(('flush', last_addr, v), to=mem_ctrl_protocol_obj)
        send(('inc_msg_cnt', 1), to=monitor_obj)

    #output("Appending value for address:",addr, "with value:", value)
    self.memory.append((1, addr, value))
    get_from_memory = True
    wait_for_memory = True

  def receive(msg=('not_found_in_memory')):
    """
    Address no found in memory
    """
    print("Addr not found in memory")
    wait_for_memory = True

  def receive(msg=('load', addr), from_=s):
    """
    Received load request from processor, load address into cache and send back acknowledgement
    """
    #output("Received LOAD request for addr %s" % addr);
    found = False
    value = ""
    for val in self.memory:
      # Cache miss logic
      if val[0] == 1 and val[1] == addr:
        found = True
        break
    if not found:
      send(('cache_miss'), to=monitor_obj)
      get_addr(addr)
    else:
      send(('cache_hit'), to=monitor_obj)
    value = self.reorder(addr, '')
    not_found_q.clear()
    #output("Sending Ack load", len(not_found_q))
    send(('ins', 'loaded', addr, value, self.id), to=monitor_obj)
    send(('completed_load', value), to=s)
    send(('inc_msg_cnt', 1), to=monitor_obj)
  
  def receive(msg=('store', addr, value), from_=s):
    """
    Received store request from processor, store value into cache and send back acknowledgement
    """
    #output("Received STORE request for addr %s" % addr);
    found = False
    for val in self.memory:
      # Cache miss logic
      if val[0] == 1 and val[1] == addr:
        found = True
        break
    if not found:
      send(('cache_miss'), to=monitor_obj)
      get_addr(addr)
    else:
      send(('cache_hit'), to=monitor_obj)
    #value = self.reorder(addr, va)
    self.reorder(addr, value)
    not_found_q.clear()
    #output("Sending Ack store", len(not_found_q))
    send(('ins', 'stored', addr, value, self.id), to=monitor_obj)
    send('completed_store', to=s)
    send(('inc_msg_cnt', 1), to=monitor_obj)
  
  def receive(msg= ('done',)):
    #print("Cache Exiting\n")
    exit()

class MI_PROTO_CTRL(process):
  """
  MI Memory Controller Class:
    - This class simulates the system bus and memory controller
    - keeps track of all addresses in the caches
    - A standalone process which serves memory requests from the caches
    - Inherits from the process class in DistAlgo
  """
  def setup(cache_protocol_objs, monitor_obj):
    self.memory_ref = dict()
    self.memory_value = dict()
  
  def run():
    await(False)
  
  def receive(msg= ('get',addr, id), from_= p):
    """
    Retrieve the requested address from memory and send it back to the cache
    """
    """ Add time delay here to mimic cache-to-memory latency """
    if addr in self.memory_ref and self.memory_ref[addr] != 0:
      #output(memory_ref)
      send(('get_from_cache', addr), to=p)
      send(('inc_msg_cnt', 1), to=monitor_obj)
    else:
      time.sleep(0.1)
      self.memory_ref[addr] = id
      if addr not in self.memory_value:
        self.memory_value[addr] = 0
      send(('found_in_memory', addr, self.memory_value[addr]), to=p)
      send(('inc_msg_cnt', 1), to=monitor_obj)

  def receive(msg= ('flush', addr, value)):
    """
    Write back to memory
    """
    time.sleep(0.1)
    self.memory_ref[addr] = 0

  def receive(msg= ('done',)):
    #print("CTRL Exiting\n")
    exit()

class Processor(process):
    """
    Processor Class:
      - This class handles the processor logic
      - reads the execution trace one instruction at a time and executes it
      - All the load/store intstructions will be send to it's cache controller process
      - Inherits from the process class in DistAlgo
      - generic to all protocol implementations
    Reference : Parag Gupta (https://github.com/karthikbox/cache_coherence/tree/p_template/main.da)
    """

    def setup(trace, protocol, monitor_obj):
      self.keep_waiting = False
      ## self.cache = Cache(protocol, CACHE_SIZE)
    
    def execute(inst):
      """
           Execute the instructions in the given execution trace 
           Reference : Parag Gupta (https://github.com/karthikbox/cache_coherence/tree/p_template/main.da)
      """
      if inst[0] == "r":
        type, addr = inst
        send(('load', addr), to=protocol)
        send(('inc_msg_cnt', 1), to=monitor_obj)
     
      elif inst[0] == "w":
        type, addr, value = inst
        send(('store', addr, value), to=protocol)
        send(('inc_msg_cnt', 1), to=monitor_obj)
      
      else:
        print("Unexpected instruction:", inst);
    
    def run():
      for inst in trace:
        keep_waiting = False
        execute(inst)
        #output("waiting for acks")
        await(keep_waiting)

      #print("Processor Exits")

    def receive(msg= ('completed_load', value)):
      """
      Receive acknowledgement from the cache controller process.
      This indicates that the instruction has been executed
      Reference : Parag Gupta (https://github.com/karthikbox/cache_coherence/tree/p_template/main.da)
      """
      #output("ACKed load\n")
      keep_waiting = True

    def receive(msg= ('completed_store')):
      """
      Receive acknowledgement from the cache controller process.
      This indicates that the instruction has been executed
      Reference : Parag Gupta (https://github.com/karthikbox/cache_coherence/tree/p_template/main.da)
      """
      #output("ACKed store\n")
      keep_waiting = True

class Monitor(process):
  """
    Processor Class:
      - This class acts as the monitor process
      - It is used to collect benchmark stats and correctness verification
      - a stand-alone process listening to all other processes
  """
  
  def setup():
    self.instructions = []
    self.total_msgs = 0
    self.cpu_time = 0
    self.elapsed_time = 0
    self.total_cache_hit = 0
    self.total_cache_miss = 0

  def receive(msg= ('cache_hit')):
    total_cache_hit += 1
   
  def receive(msg= ('cache_miss')):
    total_cache_miss += 1

  def receive(msg= ('ins', type, addr, value, cache_id)):
    """
    Collects all load/store instructions executed by the cache controller
    """
    instructions.append((type, addr, value, cache_id))

  def receive(msg= ('inc_msg_cnt', value)):
    """
    Keeps track of the total message count in the system
    """
    total_msgs = total_msgs + value
 
  def receive(msg= ('time_taken', cpu, elapsed)):
    """
    Get the elapsed time and CPU time
    """
    cpu_time = cpu
    elapsed_time = elapsed 

  def run():
    await(False)

  def receive(msg= ('done',)):
    """

    Simulation has ended, dislay the results of the simulation
    """
    print("===Load/Store global order===")
    for ins in instructions:
      print(ins[3], ": ", ins[0], ins[1], ins[2])
    print()
    print("===Benchmarks===")
    print("Total msg count:", total_msgs)
    print("Elapsed time:", elapsed_time)
    print("CPU time:", cpu_time)
    print("Cache hit:", total_cache_hit)
    print("Cache miss:", total_cache_miss)
    exit()

def get_traces(trace_dir,nprocs):
  """
  Extracts the execution traces from the given directory.
  Reference: Karthik Reddy (https://github.com/karthikbox/cache_coherence/blob/mesi_protocol/main.da)
  """
  
  trace=[]
  for i in range(nprocs):
    trace_filename='p'+str(i)+'.trace'
    f=open(os.path.join(trace_dir,trace_filename))
    insts=[]
    for line in f:      
      insts.append(line.split())
    trace.append(insts)
  return trace

def main():
    """
    main routine - generic to all protocol implementations:
      - spawn DistAlgo processes for n processors, n cache controllers and a memory controller 
      - get execution traces for each of the processors
    Reference : Parag Gupta (https://github.com/karthikbox/cache_coherence/tree/p_template/main.da)
    """

    nprocessors = int(sys.argv[1]) if len(sys.argv) > 1 else 2
    proto_name = sys.argv[2] if len(sys.argv) > 2 else 'MI'
    #trace_file = sys.argv[3] if len(sys.argv) > 3 else exit(-1)
    #trace_file = sys.argv[3] if len(sys.argv) > 3 else 'none'
    trace_dir = sys.argv[3] if len(sys.argv) > 3 else './traces'

    config(channel= 'fifo', clock= 'Lamport')

    start_cpu_time = time.process_time()
    start_elapsed_time = time.perf_counter()
    
    #trace = get_traces(trace_file)
    trace = get_traces(trace_dir,nprocessors)
    Proto_cache, Proto_ctrl = get_proto_class(proto_name)

    print('-----START-----')
    ## Start monitor process
    monitor_obj = new(Monitor, num=1)
    setup(monitor_obj, ())
    start(monitor_obj)
    
    ## Initialize protocol objs for caches and controller
    mem_ctrl_protocol_obj = new(Proto_ctrl, num=1)
    protocol_objs = new(Proto_cache, num=nprocessors)
    
    ## Setup Protocol for ctrller
    setup(mem_ctrl_protocol_obj, (protocol_objs,monitor_obj))
    start(mem_ctrl_protocol_obj)

    ## Setup Protocols for caches
    for proto_obj in protocol_objs:
      setup(proto_obj, (mem_ctrl_protocol_obj, protocol_objs - {proto_obj}, CACHE_SIZE, monitor_obj))
      start(proto_obj)

    ## Setup Processors
    processors = new(Processor, num= nprocessors)
    
    ## temp lists for iterating
    processors_list = list(processors)
    protocol_objs_list = list(protocol_objs)
    for i in range(nprocessors): 
      setup(processors_list[i], (trace[i], protocol_objs_list[i], monitor_obj))
    
    start(processors)
    
    ## Exiting logic  
    for p in processors: 
      p.join()

    da.send(('done',), to= protocol_objs)
    for m in protocol_objs:
      m.join()

    da.send(('done',), to= mem_ctrl_protocol_obj)
    for m in mem_ctrl_protocol_obj:
      m.join()

    end_cpu_time = time.process_time()
    end_elapsed_time = time.perf_counter()

    da.send(('time_taken', end_cpu_time-start_cpu_time, end_elapsed_time-start_elapsed_time), to= monitor_obj)
    da.send(('done',), to= monitor_obj)
    for monitor in monitor_obj:
      monitor.join() 
    print('-----END-----')

